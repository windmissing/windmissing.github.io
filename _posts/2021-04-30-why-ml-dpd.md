---
layout: post
title: "我为什么要做ML PA"
category: [Machine Learning]
tags: []
---

[第6章 深度前馈网络](https://windmissing.github.io/Bible-DeepLearning/Chapter6/0Introduction.html)，这是花书深度学习相关内容的第一篇，原以为只是普通的介绍，没有读出任何感觉。直到我做了一年的ML PA，今日整理笔记时再次通读了这一篇，一文惊醒梦中人。  

这一篇从“线性模型”开始，引入到了DL历史的深层逻辑。先回顾一下它的主要内容。  
1. 介绍线性模型的优点和缺点：  
优点：能通过闭解形式或凸优化形式高效且可靠地拟合。  
缺点：只能表达线性关系，无法理解任何两个输入变量间的相互作用。  
2. 介绍针对缺点的解决方法，引入kernal $\phi$    
3. 选择$\phi$的三种手段：（1）使用一个通用的$\phi$（2）手动设计$\phi$（3）让机器自己学习$\phi$

通信领域的DPD算法与机器学习是八竿子打不着的关系，但这一段内容却是对DPD算法的现状和我想做的事情做了精准的概括。  

传统的DPD算法本质上是一个线性模型，我们能够方便地使用LS求解DPD参数，正是沾了线性模型的光。因为线性模型的优点就是“能通过闭解形式或凸优化形式高效且可靠地拟合。”  

由于PA的非线性，单纯的线性模型肯定是解决不了问题的。解决方案就是kernel。而各种DPD算法的改进，实际上就是设计各种不同的kernel。  

设计kernel的方法有很多，文中第一条是使用一个通用的kernel。并且指出，只要kernel的维度足够高，就可以拟合任何训练数据。虽然我没有见谁在DPD算法中使用文中所提的RBF kernel，但是在DPD算法历史中，确实存在这样一种通用的kernel，我们把它称为Generic Memory Polynomial(GMP)算法。  

GMP算法是传统DPD算法的基础。几乎所有的DPD算法都是基于GMP算法的改进。这些改进主要是依据（1）根据业务原理设计更合适的kernel（2）用更少的资源实现更高的维度。这些改进需要透彻理解数据、数学和硬件的特点，有时需要根据特殊的场景做专门的调整。正如文中所说：“手动地设计kernel这种方法，需要人们数十年的努力、从业者擅长特定领域，并且不同领域之间很难迁移”。同时也说明，这一方法“**在深度学习出现以前是主流**”，但现在不一样，我们该试试新的方法了。  

用深度学习的方法去学习kernel，这正是我想做的事，也是我正在努力去做的事。虽然我现在在做的是ML PA，不是ML DPD，但熟悉这一领域的人都知道，DPD算法与PA行为模型是相通的。做ML PA正是为以后做ML DPD做准备。

<!-- more -->